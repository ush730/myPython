{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST (손글씨)\n",
    "data = datasets.mnist\n",
    "(train_x, train_y), (test_x, test_y) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_x[2], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000, 28, 28), (15000, 28, 28), (45000,), (15000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, valid_x.shape, train_y.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 9, 8, 0, 5, 8, 6, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 입력하기 위해 차원 변경\n",
    "# 스케일 조정(MinMax) 색상범위값 255로 나눔\n",
    "train_x = train_x.reshape(train_x.shape[0],28*28)/255\n",
    "valid_x = valid_x.reshape(valid_x.shape[0],28*28)/255\n",
    "test_x = test_x.reshape(test_x.shape[0],28*28)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000, 784), (15000, 784), (10000, 784))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, valid_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 9, 8, 0, 5, 8, 6, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label(정답)의 categorical값 -> 원핫인코딩\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_y = to_categorical(train_y)\n",
    "valid_y = to_categorical(valid_y)\n",
    "test_y = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망(ANN) 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from tensorflow.keras.models import Sequential # 모델객체생성을 위한 클래스\n",
    "from tensorflow.keras.layers import Dense # 레이어추가를 위한 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.7399 - accuracy: 0.7676 - val_loss: 0.2280 - val_accuracy: 0.9325\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.9466 - val_loss: 0.1642 - val_accuracy: 0.9515\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.9622 - val_loss: 0.1392 - val_accuracy: 0.9580\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1016 - accuracy: 0.9693 - val_loss: 0.1322 - val_accuracy: 0.9608\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0822 - accuracy: 0.9748 - val_loss: 0.1268 - val_accuracy: 0.9625\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0697 - accuracy: 0.9781 - val_loss: 0.1178 - val_accuracy: 0.9670\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0574 - accuracy: 0.9822 - val_loss: 0.1202 - val_accuracy: 0.9677\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0486 - accuracy: 0.9842 - val_loss: 0.1180 - val_accuracy: 0.9668\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.1199 - val_accuracy: 0.9685\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0369 - accuracy: 0.9880 - val_loss: 0.1183 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2267dcde490>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤시드값\n",
    "tf.random.set_seed(14)\n",
    "\n",
    "# 모델 구현\n",
    "model = Sequential() # 객체 생성\n",
    "\n",
    "# 데이터 입력받는 레이어\n",
    "# Dense(출력데이터차원, 활성화함수, 입력데이터차원)\n",
    "model.add(Dense(64, activation='relu', input_shape=(28*28,)))\n",
    "\n",
    "# 레이어 추가\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# 출력레이어\n",
    "# label 값의 종류만큼 차원 지정\n",
    "# 활성화함수 -> softmax\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# 모델 설정\n",
    "# compile()\n",
    "# 최적화기법 : adam(learning_rate=0.001)\n",
    "# 손실함수 : categorical_crossentropy\n",
    "# 평가지표 : accuracy\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습\n",
    "# epochs : 학습횟수\n",
    "# validation_data : 검증데이터\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=50, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.1129 - accuracy: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11291469633579254, 0.970300018787384]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트데이터 평가\n",
    "# 손실값, 정확도\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8944 - accuracy: 0.3853 - val_loss: 0.6804 - val_accuracy: 0.8628\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.5534 - accuracy: 0.8858 - val_loss: 0.3447 - val_accuracy: 0.9198\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3095 - accuracy: 0.9282 - val_loss: 0.2683 - val_accuracy: 0.9327\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2349 - accuracy: 0.9449 - val_loss: 0.2255 - val_accuracy: 0.9415\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.9518 - val_loss: 0.2044 - val_accuracy: 0.9454\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1620 - accuracy: 0.9592 - val_loss: 0.1849 - val_accuracy: 0.9507\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1344 - accuracy: 0.9655 - val_loss: 0.1753 - val_accuracy: 0.9526\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1157 - accuracy: 0.9703 - val_loss: 0.1683 - val_accuracy: 0.9553\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1024 - accuracy: 0.9729 - val_loss: 0.1803 - val_accuracy: 0.9509\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9758 - val_loss: 0.1592 - val_accuracy: 0.9563\n",
      "Epoch 1/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.6718 - accuracy: 0.8257 - val_loss: 0.2004 - val_accuracy: 0.9417\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1712 - accuracy: 0.9513 - val_loss: 0.1450 - val_accuracy: 0.9583\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1139 - accuracy: 0.9672 - val_loss: 0.1285 - val_accuracy: 0.9639\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0864 - accuracy: 0.9744 - val_loss: 0.1225 - val_accuracy: 0.9653\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0706 - accuracy: 0.9792 - val_loss: 0.1158 - val_accuracy: 0.9673\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0566 - accuracy: 0.9828 - val_loss: 0.1172 - val_accuracy: 0.9674\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 0.1163 - val_accuracy: 0.9666\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0400 - accuracy: 0.9883 - val_loss: 0.1186 - val_accuracy: 0.9682\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0383 - accuracy: 0.9883 - val_loss: 0.1364 - val_accuracy: 0.9641\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.1235 - val_accuracy: 0.9678\n",
      "Epoch 1/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.7399 - accuracy: 0.7676 - val_loss: 0.2280 - val_accuracy: 0.9325\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.9466 - val_loss: 0.1642 - val_accuracy: 0.9515\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1230 - accuracy: 0.9622 - val_loss: 0.1392 - val_accuracy: 0.9580\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1016 - accuracy: 0.9693 - val_loss: 0.1322 - val_accuracy: 0.9608\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0822 - accuracy: 0.9748 - val_loss: 0.1268 - val_accuracy: 0.9625\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.9781 - val_loss: 0.1178 - val_accuracy: 0.9670\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0574 - accuracy: 0.9822 - val_loss: 0.1202 - val_accuracy: 0.9677\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0486 - accuracy: 0.9842 - val_loss: 0.1180 - val_accuracy: 0.9668\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.1199 - val_accuracy: 0.9685\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0369 - accuracy: 0.9880 - val_loss: 0.1183 - val_accuracy: 0.9703\n"
     ]
    }
   ],
   "source": [
    " for func in ['sigmoid','tanh','relu']:\n",
    "    # 랜덤시드값\n",
    "    tf.random.set_seed(14)\n",
    "\n",
    "    # 모델 구현\n",
    "    model = Sequential() # 객체 생성\n",
    "\n",
    "    # 데이터 입력받는 레이어\n",
    "    # Dense(출력데이터차원, 활성화함수, 입력데이터차원)\n",
    "    model.add(Dense(64, activation=func, input_shape=(28*28,)))\n",
    "\n",
    "    # 레이어 추가\n",
    "    model.add(Dense(32, activation=func))\n",
    "    model.add(Dense(32, activation=func))\n",
    "    model.add(Dense(32, activation=func))\n",
    "\n",
    "    # 출력레이어\n",
    "    # label 값의 종류만큼 차원 지정\n",
    "    # 활성화함수 -> softmax\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # 모델 설정\n",
    "    # compile()\n",
    "    # 최적화기법 : adam(learning_rate=0.001)\n",
    "    # 손실함수 : categorical_crossentropy\n",
    "    # 평가지표 : accuracy\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 학습\n",
    "    # epochs : 학습횟수\n",
    "    # validation_data : 검증데이터\n",
    "    model.fit(train_x, train_y, epochs=10, batch_size=50, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.27800977, 0.30724832, 0.41474187], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax 함수\n",
    "tf.nn.softmax([0.1,0.2,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27800977, 0.30724832, 0.41474187], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax([0.1,0.2,0.5]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax([0.1,0.2,0.5]).numpy().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 설정(compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.7399 - accuracy: 0.7676 - val_loss: 0.2280 - val_accuracy: 0.9325\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1830 - accuracy: 0.9466 - val_loss: 0.1642 - val_accuracy: 0.9515\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.9622 - val_loss: 0.1392 - val_accuracy: 0.9580\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1016 - accuracy: 0.9693 - val_loss: 0.1322 - val_accuracy: 0.9608\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0822 - accuracy: 0.9748 - val_loss: 0.1268 - val_accuracy: 0.9625\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0697 - accuracy: 0.9781 - val_loss: 0.1178 - val_accuracy: 0.9670\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0574 - accuracy: 0.9822 - val_loss: 0.1202 - val_accuracy: 0.9677\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0486 - accuracy: 0.9842 - val_loss: 0.1180 - val_accuracy: 0.9668\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.1199 - val_accuracy: 0.9685\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0369 - accuracy: 0.9880 - val_loss: 0.1183 - val_accuracy: 0.9703\n",
      "Epoch 1/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7578 - accuracy: 0.4100 - val_loss: 0.4771 - val_accuracy: 0.8643\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.4339 - accuracy: 0.8750 - val_loss: 0.3525 - val_accuracy: 0.8995\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.3287 - accuracy: 0.9044 - val_loss: 0.2967 - val_accuracy: 0.9132\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.2838 - accuracy: 0.9201 - val_loss: 0.2606 - val_accuracy: 0.9238\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.9277 - val_loss: 0.2448 - val_accuracy: 0.9282\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.2213 - accuracy: 0.9350 - val_loss: 0.2091 - val_accuracy: 0.9402\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1874 - accuracy: 0.9459 - val_loss: 0.1926 - val_accuracy: 0.9443\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1711 - accuracy: 0.9492 - val_loss: 0.1829 - val_accuracy: 0.9479\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1584 - accuracy: 0.9527 - val_loss: 0.1788 - val_accuracy: 0.9472\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1472 - accuracy: 0.9571 - val_loss: 0.1672 - val_accuracy: 0.9490\n",
      "Epoch 1/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.6870 - accuracy: 0.7885 - val_loss: 0.2108 - val_accuracy: 0.9367\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9433 - val_loss: 0.1596 - val_accuracy: 0.9530\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1282 - accuracy: 0.9620 - val_loss: 0.1425 - val_accuracy: 0.9591\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1056 - accuracy: 0.9690 - val_loss: 0.1336 - val_accuracy: 0.9615\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0874 - accuracy: 0.9730 - val_loss: 0.1320 - val_accuracy: 0.9632\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0740 - accuracy: 0.9763 - val_loss: 0.1333 - val_accuracy: 0.9659\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9814 - val_loss: 0.1310 - val_accuracy: 0.9667\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0591 - accuracy: 0.9833 - val_loss: 0.1356 - val_accuracy: 0.9665\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0508 - accuracy: 0.9848 - val_loss: 0.1407 - val_accuracy: 0.9654\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0460 - accuracy: 0.9866 - val_loss: 0.1419 - val_accuracy: 0.9674\n"
     ]
    }
   ],
   "source": [
    "# import (optimizer 클래스)\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "for opt in [Adam(), SGD(), RMSprop()]:\n",
    "    # 랜덤시드값\n",
    "    tf.random.set_seed(14)\n",
    "\n",
    "    # 모델 구현\n",
    "    model = Sequential() # 객체 생성\n",
    "\n",
    "    # 데이터 입력받는 레이어\n",
    "    # Dense(출력데이터차원, 활성화함수, 입력데이터차원)\n",
    "    model.add(Dense(64, activation='relu', input_shape=(28*28,)))\n",
    "\n",
    "    # 레이어 추가\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    # 출력레이어\n",
    "    # label 값의 종류만큼 차원 지정\n",
    "    # 활성화함수 -> softmax\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # 모델 설정\n",
    "    # compile()\n",
    "    # 최적화기법 : adam(learning_rate=0.001)\n",
    "    # 손실함수 : categorical_crossentropy\n",
    "    # 평가지표 : accuracy\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 학습\n",
    "    # epochs : 학습횟수\n",
    "    # validation_data : 검증데이터\n",
    "    model.fit(train_x, train_y, epochs=10, batch_size=50, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.7399 - accuracy: 0.7676 - val_loss: 0.2280 - val_accuracy: 0.9325\n",
      "Epoch 2/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.9466 - val_loss: 0.1642 - val_accuracy: 0.9515\n",
      "Epoch 3/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.9622 - val_loss: 0.1392 - val_accuracy: 0.9580\n",
      "Epoch 4/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1016 - accuracy: 0.9693 - val_loss: 0.1322 - val_accuracy: 0.9608\n",
      "Epoch 5/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0822 - accuracy: 0.9748 - val_loss: 0.1268 - val_accuracy: 0.9625\n",
      "Epoch 6/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.9781 - val_loss: 0.1178 - val_accuracy: 0.9670\n",
      "Epoch 7/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0574 - accuracy: 0.9822 - val_loss: 0.1202 - val_accuracy: 0.9677\n",
      "Epoch 8/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0486 - accuracy: 0.9842 - val_loss: 0.1180 - val_accuracy: 0.9668\n",
      "Epoch 9/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.1199 - val_accuracy: 0.9685\n",
      "Epoch 10/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0369 - accuracy: 0.9880 - val_loss: 0.1183 - val_accuracy: 0.9703\n",
      "Epoch 11/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 0.1436 - val_accuracy: 0.9641\n",
      "Epoch 12/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0311 - accuracy: 0.9901 - val_loss: 0.1233 - val_accuracy: 0.9688\n",
      "Epoch 13/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 0.1284 - val_accuracy: 0.9694\n",
      "Epoch 14/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.1412 - val_accuracy: 0.9686\n",
      "Epoch 15/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.1332 - val_accuracy: 0.9689\n",
      "Epoch 16/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 0.1495 - val_accuracy: 0.9678\n",
      "Epoch 17/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.1605 - val_accuracy: 0.9677\n",
      "Epoch 18/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.1540 - val_accuracy: 0.9651\n",
      "Epoch 19/50\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0260 - accuracy: 0.9906 - val_loss: 0.1679 - val_accuracy: 0.9654\n",
      "Epoch 20/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.1600 - val_accuracy: 0.9683\n",
      "Epoch 21/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.1488 - val_accuracy: 0.9705\n",
      "Epoch 22/50\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.1785 - val_accuracy: 0.9653\n",
      "Epoch 23/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.1890 - val_accuracy: 0.9639\n",
      "Epoch 24/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.1525 - val_accuracy: 0.9707\n",
      "Epoch 25/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.1653 - val_accuracy: 0.9671\n",
      "Epoch 26/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1834 - val_accuracy: 0.9664\n",
      "Epoch 27/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.1659 - val_accuracy: 0.9707\n",
      "Epoch 28/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.1893 - val_accuracy: 0.9657\n",
      "Epoch 29/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.1967 - val_accuracy: 0.9667\n",
      "Epoch 30/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.1830 - val_accuracy: 0.9680\n",
      "Epoch 31/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.1709 - val_accuracy: 0.9707\n",
      "Epoch 32/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.1843 - val_accuracy: 0.9703\n",
      "Epoch 33/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.1970 - val_accuracy: 0.9679\n",
      "Epoch 34/50\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.1751 - val_accuracy: 0.9696\n",
      "Epoch 35/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.1834 - val_accuracy: 0.9692\n",
      "Epoch 36/50\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.1773 - val_accuracy: 0.9695\n",
      "Epoch 37/50\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.2132 - val_accuracy: 0.9649\n",
      "Epoch 38/50\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.1973 - val_accuracy: 0.9674\n",
      "Epoch 39/50\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.1965 - val_accuracy: 0.9675\n",
      "Epoch 40/50\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.1848 - val_accuracy: 0.9705\n",
      "Epoch 41/50\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.1966 - val_accuracy: 0.9689\n",
      "Epoch 42/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1967 - val_accuracy: 0.9691\n",
      "Epoch 43/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.1887 - val_accuracy: 0.9704\n",
      "Epoch 44/50\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.1951 - val_accuracy: 0.9687\n",
      "Epoch 45/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.1918 - val_accuracy: 0.9691\n",
      "Epoch 46/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1961 - val_accuracy: 0.9702\n",
      "Epoch 47/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.2602 - val_accuracy: 0.9647\n",
      "Epoch 48/50\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.2012 - val_accuracy: 0.9704\n",
      "Epoch 49/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.2034 - val_accuracy: 0.9711\n",
      "Epoch 50/50\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.1910 - val_accuracy: 0.9725\n"
     ]
    }
   ],
   "source": [
    "# 랜덤시드값\n",
    "tf.random.set_seed(14)\n",
    "\n",
    "# 모델 구현\n",
    "model = Sequential() # 객체 생성\n",
    "\n",
    "# 데이터 입력받는 레이어\n",
    "# Dense(출력데이터차원, 활성화함수, 입력데이터차원)\n",
    "model.add(Dense(64, activation='relu', input_shape=(28*28,)))\n",
    "\n",
    "# 레이어 추가\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# 출력레이어\n",
    "# label 값의 종류만큼 차원 지정\n",
    "# 활성화함수 -> softmax\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# 모델 설정\n",
    "# compile()\n",
    "# 최적화기법 : adam(learning_rate=0.001)\n",
    "# 손실함수 : categorical_crossentropy\n",
    "# 평가지표 : accuracy\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습\n",
    "# epochs : 학습횟수\n",
    "# validation_data : 검증데이터\n",
    "history = model.fit(train_x, train_y, epochs=50, batch_size=50, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.41582000255584717,\n",
       "  0.17429296672344208,\n",
       "  0.1267540156841278,\n",
       "  0.10148102045059204,\n",
       "  0.08169137686491013,\n",
       "  0.07185032218694687,\n",
       "  0.06380624324083328,\n",
       "  0.05304820463061333,\n",
       "  0.047454867511987686,\n",
       "  0.043313197791576385,\n",
       "  0.03721670061349869,\n",
       "  0.03560103476047516,\n",
       "  0.03013461083173752,\n",
       "  0.030423160642385483,\n",
       "  0.027961699292063713,\n",
       "  0.02528953365981579,\n",
       "  0.022057054564356804,\n",
       "  0.02067926898598671,\n",
       "  0.02414652705192566,\n",
       "  0.01914256438612938,\n",
       "  0.02047981135547161,\n",
       "  0.019645368680357933,\n",
       "  0.01743701659142971,\n",
       "  0.013939818367362022,\n",
       "  0.018737370148301125,\n",
       "  0.015359858982264996,\n",
       "  0.0156693197786808,\n",
       "  0.014269832521677017,\n",
       "  0.011800209991633892,\n",
       "  0.016002675518393517,\n",
       "  0.013820881024003029,\n",
       "  0.014576786197721958,\n",
       "  0.013115410692989826,\n",
       "  0.014434992335736752,\n",
       "  0.012598257511854172,\n",
       "  0.011649582535028458,\n",
       "  0.009397419169545174,\n",
       "  0.011532207950949669,\n",
       "  0.013303004205226898,\n",
       "  0.01097437646239996,\n",
       "  0.00986180454492569,\n",
       "  0.011296268552541733,\n",
       "  0.011795549653470516,\n",
       "  0.009616629220545292,\n",
       "  0.009598685428500175,\n",
       "  0.010933050885796547,\n",
       "  0.009980875998735428,\n",
       "  0.004746719263494015,\n",
       "  0.015272621996700764,\n",
       "  0.003456096164882183],\n",
       " 'accuracy': [0.8756444454193115,\n",
       "  0.9481333494186401,\n",
       "  0.9618666768074036,\n",
       "  0.9696221947669983,\n",
       "  0.9746888875961304,\n",
       "  0.9778222441673279,\n",
       "  0.9801111221313477,\n",
       "  0.9831777811050415,\n",
       "  0.984844446182251,\n",
       "  0.9863777756690979,\n",
       "  0.9881333112716675,\n",
       "  0.9885555505752563,\n",
       "  0.9903333187103271,\n",
       "  0.9894888997077942,\n",
       "  0.9910888671875,\n",
       "  0.9912889003753662,\n",
       "  0.9924222230911255,\n",
       "  0.9928666949272156,\n",
       "  0.9914888739585876,\n",
       "  0.9935333132743835,\n",
       "  0.9935555458068848,\n",
       "  0.9935555458068848,\n",
       "  0.9937777519226074,\n",
       "  0.9954444169998169,\n",
       "  0.9939777851104736,\n",
       "  0.994688868522644,\n",
       "  0.9951111078262329,\n",
       "  0.995377779006958,\n",
       "  0.9961333274841309,\n",
       "  0.9944666624069214,\n",
       "  0.9958444237709045,\n",
       "  0.9951111078262329,\n",
       "  0.9956666827201843,\n",
       "  0.9956222176551819,\n",
       "  0.996222198009491,\n",
       "  0.9962666630744934,\n",
       "  0.9974889159202576,\n",
       "  0.9964222311973572,\n",
       "  0.9955111145973206,\n",
       "  0.9962888956069946,\n",
       "  0.9966889023780823,\n",
       "  0.9961110949516296,\n",
       "  0.9964666962623596,\n",
       "  0.9970444440841675,\n",
       "  0.9969555735588074,\n",
       "  0.9966444373130798,\n",
       "  0.9965333342552185,\n",
       "  0.9986222386360168,\n",
       "  0.9950000047683716,\n",
       "  0.9986888766288757],\n",
       " 'val_loss': [0.22800718247890472,\n",
       "  0.16417132318019867,\n",
       "  0.13923929631710052,\n",
       "  0.13218951225280762,\n",
       "  0.1267773061990738,\n",
       "  0.11778575927019119,\n",
       "  0.12018332630395889,\n",
       "  0.1180102527141571,\n",
       "  0.11992619186639786,\n",
       "  0.11826371401548386,\n",
       "  0.14358997344970703,\n",
       "  0.12325318902730942,\n",
       "  0.12836410105228424,\n",
       "  0.14116650819778442,\n",
       "  0.13320282101631165,\n",
       "  0.14945341646671295,\n",
       "  0.160486102104187,\n",
       "  0.15402251482009888,\n",
       "  0.1679360717535019,\n",
       "  0.15999293327331543,\n",
       "  0.1487661749124527,\n",
       "  0.17850905656814575,\n",
       "  0.18899387121200562,\n",
       "  0.15251342952251434,\n",
       "  0.16534532606601715,\n",
       "  0.1834390014410019,\n",
       "  0.16590000689029694,\n",
       "  0.1892908215522766,\n",
       "  0.19670288264751434,\n",
       "  0.1829656958580017,\n",
       "  0.17094109952449799,\n",
       "  0.1842964142560959,\n",
       "  0.19702504575252533,\n",
       "  0.1751132756471634,\n",
       "  0.1834200620651245,\n",
       "  0.17726321518421173,\n",
       "  0.21321657299995422,\n",
       "  0.19734853506088257,\n",
       "  0.19649438560009003,\n",
       "  0.18479779362678528,\n",
       "  0.19661341607570648,\n",
       "  0.1966962218284607,\n",
       "  0.18870919942855835,\n",
       "  0.19513733685016632,\n",
       "  0.19183948636054993,\n",
       "  0.19614136219024658,\n",
       "  0.2601594924926758,\n",
       "  0.20123302936553955,\n",
       "  0.20335297286510468,\n",
       "  0.19097845256328583],\n",
       " 'val_accuracy': [0.9324666857719421,\n",
       "  0.951533317565918,\n",
       "  0.9580000042915344,\n",
       "  0.9607999920845032,\n",
       "  0.9624666571617126,\n",
       "  0.9670000076293945,\n",
       "  0.9676666855812073,\n",
       "  0.9667999744415283,\n",
       "  0.9685333371162415,\n",
       "  0.9702666401863098,\n",
       "  0.9641333222389221,\n",
       "  0.9688000082969666,\n",
       "  0.9693999886512756,\n",
       "  0.9685999751091003,\n",
       "  0.9688666462898254,\n",
       "  0.9678000211715698,\n",
       "  0.9676666855812073,\n",
       "  0.96506667137146,\n",
       "  0.965399980545044,\n",
       "  0.9682666659355164,\n",
       "  0.9705333113670349,\n",
       "  0.9652666449546814,\n",
       "  0.9639333486557007,\n",
       "  0.9706666469573975,\n",
       "  0.9671333432197571,\n",
       "  0.9664000272750854,\n",
       "  0.9706666469573975,\n",
       "  0.9657333493232727,\n",
       "  0.9666666388511658,\n",
       "  0.9679999947547913,\n",
       "  0.9706666469573975,\n",
       "  0.9703333377838135,\n",
       "  0.9679333567619324,\n",
       "  0.9696000218391418,\n",
       "  0.9692000150680542,\n",
       "  0.9695333242416382,\n",
       "  0.9649333357810974,\n",
       "  0.9674000144004822,\n",
       "  0.9675333499908447,\n",
       "  0.970466673374176,\n",
       "  0.9688666462898254,\n",
       "  0.9690666794776917,\n",
       "  0.9703999757766724,\n",
       "  0.9687333106994629,\n",
       "  0.9690666794776917,\n",
       "  0.9702000021934509,\n",
       "  0.964733362197876,\n",
       "  0.9703999757766724,\n",
       "  0.9710666537284851,\n",
       "  0.9724666476249695]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습데이터 로스\n",
    "plt.plot(history.history['loss'], c='r')\n",
    "# 검증데이터 로스\n",
    "plt.plot(history.history['val_loss'], c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.1965 - accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1964758038520813, 0.9732999801635742]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50회 학습한 모델(정확도 99%)로 테스트데이터 예측\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 혼동행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 968,    0,    0,    0,    2,    1,    4,    3,    2,    0],\n",
       "       [   0, 1122,    2,    2,    0,    0,    2,    1,    6,    0],\n",
       "       [   1,    2, 1013,    6,    1,    0,    1,    5,    3,    0],\n",
       "       [   0,    0,    0,  990,    0,    8,    0,    6,    5,    1],\n",
       "       [   3,    0,    2,    0,  955,    0,    9,    1,    0,   12],\n",
       "       [   3,    1,    0,   13,    3,  855,   10,    0,    6,    1],\n",
       "       [   3,    2,    1,    1,    3,    4,  938,    1,    5,    0],\n",
       "       [   1,    2,    9,    7,    2,    0,    0,  997,    7,    3],\n",
       "       [  10,    2,    5,    5,    4,    6,    4,    5,  929,    4],\n",
       "       [   2,    3,    0,    7,   12,    3,    0,    8,    8,  966]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "pred = model.predict(test_x)\n",
    "# 실제:[1,0,1], 예측:[1,0,0]\n",
    "confusion_matrix(np.argmax(test_y, axis=1), np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류보고서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.96      0.98      0.97      1010\n",
      "           4       0.97      0.97      0.97       982\n",
      "           5       0.97      0.96      0.97       892\n",
      "           6       0.97      0.98      0.97       958\n",
      "           7       0.97      0.97      0.97      1028\n",
      "           8       0.96      0.95      0.96       974\n",
      "           9       0.98      0.96      0.97      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.argmax(test_y, axis=1), np.argmax(pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32941176, 0.7254902 , 0.62352941,\n",
       "        0.59215686, 0.23529412, 0.14117647, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "        0.94509804, 0.77647059, 0.77647059, 0.77647059, 0.77647059,\n",
       "        0.77647059, 0.77647059, 0.77647059, 0.77647059, 0.66666667,\n",
       "        0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.2627451 , 0.44705882,\n",
       "        0.28235294, 0.44705882, 0.63921569, 0.89019608, 0.99607843,\n",
       "        0.88235294, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
       "        0.89803922, 0.99607843, 0.99607843, 0.54901961, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.06666667, 0.25882353, 0.05490196, 0.2627451 ,\n",
       "        0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "        0.99607843, 0.41568627, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3254902 , 0.99215686, 0.81960784, 0.07058824,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.08627451, 0.91372549,\n",
       "        1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.50588235, 0.99607843, 0.93333333, 0.17254902,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.23137255, 0.97647059,\n",
       "        0.99607843, 0.24313725, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.52156863, 0.99607843, 0.73333333, 0.01960784,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03529412, 0.80392157,\n",
       "        0.97254902, 0.22745098, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.49411765, 0.99607843, 0.71372549, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.29411765, 0.98431373,\n",
       "        0.94117647, 0.22352941, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0745098 , 0.86666667, 0.99607843, 0.65098039, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.79607843, 0.99607843,\n",
       "        0.85882353, 0.1372549 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.14901961, 0.99607843, 0.99607843, 0.30196078, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12156863, 0.87843137, 0.99607843,\n",
       "        0.45098039, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.52156863, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.23921569, 0.94901961, 0.99607843,\n",
       "        0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4745098 , 0.99607843, 0.99607843, 0.85882353, 0.15686275,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
       "        0.81176471, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(test_x[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.2999294e-15, 5.5027601e-15, 1.6231711e-13, 1.7471750e-12,\n",
       "        2.6111574e-14, 1.9312836e-21, 3.1388645e-20, 1.0000000e+00,\n",
       "        1.1228649e-14, 2.7692071e-10]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확률값을 출력\n",
    "model.predict(np.expand_dims(test_x[0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sundooedu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label값으로 출력\n",
    "model.predict_classes(np.expand_dims(test_x[0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.1.48-cp38-cp38-win_amd64.whl (34.9 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\sundooedu\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.1.48\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('2.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# 이미지 리사이징\n",
    "img = cv2.resize(img, None, fx=28/img.shape[1], fy=28/img.shape[0])\n",
    "img = img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img,'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.8178624e-03, 2.0626435e-07, 1.5564671e-02, 6.7274011e-04,\n",
       "        7.6886371e-02, 4.8136328e-05, 9.0300661e-01, 1.3913692e-06,\n",
       "        3.3617778e-07, 1.7172352e-06]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(img,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(np.expand_dims(img,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(np.expand_dims(test_x[1],0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
